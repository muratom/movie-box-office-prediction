{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KjYuT1Vl3Bo"
      },
      "outputs": [],
      "source": [
        "class Config():\n",
        "  def __init__(\n",
        "    self,\n",
        "    num_classes,\n",
        "    num_epochs,\n",
        "    batch_size,\n",
        "    learning_rate,\n",
        "    early_stopping_patience,\n",
        "    early_stopping_min_delta,\n",
        "    use_saved_models,\n",
        "    train_size,\n",
        "    test_size,\n",
        "    val_size,\n",
        "    filename_prefix,\n",
        "    poster_shape,\n",
        "  ):\n",
        "    self.num_classes = num_classes\n",
        "    self.num_epochs = num_epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.learning_rate = learning_rate\n",
        "    self.early_stopping_patience = early_stopping_patience\n",
        "    self.early_stopping_min_delta = early_stopping_min_delta\n",
        "\n",
        "    self.use_saved_models = use_saved_models\n",
        "\n",
        "    self.train_size = train_size\n",
        "    self.test_size = test_size\n",
        "    self.val_size = val_size\n",
        "\n",
        "    self.filename_prefix = filename_prefix\n",
        "\n",
        "    self.poster_shape = poster_shape\n",
        "\n",
        "cfg = Config(\n",
        "    num_classes=4,\n",
        "    num_epochs=100, # Due to dropout\n",
        "    batch_size = 64,\n",
        "    learning_rate = 0.01,\n",
        "    early_stopping_patience = 10, # Due to dropout\n",
        "    early_stopping_min_delta = 0.01,\n",
        "    use_saved_models = False,\n",
        "    train_size = 0.9,\n",
        "    test_size = 0.05,\n",
        "    val_size = 0.05,\n",
        "    filename_prefix = './4_bor_poster_postreleased_own/4_bor_poster_postreleased_own',\n",
        "    poster_shape = (128, 128),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOwP3Cm6l3Bq"
      },
      "source": [
        "# Обработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHMMEdwxl3Bs"
      },
      "source": [
        "## Очистка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLSd3N_Ll3Bt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "from dateutil.parser import parse\n",
        "from pathlib import Path\n",
        "\n",
        "df = pd.read_csv('./movie_dataset.csv', index_col=0)\n",
        "\n",
        "to_drop = [\n",
        "    'id', \n",
        "    'tagline', \n",
        "    'overview', \n",
        "    'vote_count', \n",
        "    'original_title', \n",
        "    'title', \n",
        "    'spoken_languages',\n",
        "    'original_language',\n",
        "]\n",
        "df = df.drop(columns=to_drop)\n",
        "\n",
        "df['budget'] = df['budget'].replace({0: np.NAN})\n",
        "df['revenue'] = df['revenue'].replace({0: np.NAN})\n",
        "df['runtime'] = df['runtime'].replace({0: np.NAN})\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df = df[df['status'] == 'Released']\n",
        "df = df.drop(columns=['status'], axis=1)\n",
        "\n",
        "literal_eval_cols = ['genres', 'production_countries', 'production_companies', 'actors']\n",
        "\n",
        "for col in literal_eval_cols:\n",
        "    df[col] = df.apply(lambda x: literal_eval(x[col]), axis=1)\n",
        "\n",
        "df['production_company'] = df.apply(lambda x: x['production_companies'][0], axis=1)\n",
        "df['production_country'] = df.apply(lambda x: x['production_countries'][0], axis=1)\n",
        "df = df.drop(columns=['production_companies', 'production_countries'], axis=1)\n",
        "\n",
        "to_delete = ['M/PG', 'GP', 'Approved', 'M', 'Not Rated']\n",
        "df = df[~df['mpaa'].isin(to_delete)]\n",
        "\n",
        "df = df[df['actors'].map(len) == 3]\n",
        "df = df.join(pd.DataFrame(df['actors'].values.tolist(), df.index, ['actor_1', 'actor_2', 'actor_3']))\n",
        "df = df.drop(['actors'], axis=1)\n",
        "\n",
        "m = df.apply(lambda x: parse(x['release_date']).month, axis=1)\n",
        "df = df.join(m.rename('release_month'))\n",
        "df = df.drop(columns=['release_date'], axis=1)\n",
        "\n",
        "posters = Path('./posters')\n",
        "imdb_ids = [x.name[:-len('.jpg')] for x in posters.glob('*.jpg')]\n",
        "df = df[df['imdb_id'].isin(imdb_ids)]\n",
        "df['poster'] = df.apply(lambda x: f'./posters/{x[\"imdb_id\"]}.jpg', axis=1)\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAmYDB-2l3Bt"
      },
      "source": [
        "## Формирование целевой переменной"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiT16VvUl3Bu"
      },
      "outputs": [],
      "source": [
        "def get_class(row):\n",
        "  R = row['revenue']\n",
        "  B = row['budget']\n",
        "  if R < B:\n",
        "    return 0\n",
        "  elif B <= R < 2*B:\n",
        "    return 1\n",
        "  elif 2*B <= R < 4*B:\n",
        "    return 2\n",
        "  elif 4*B <= R:\n",
        "    return 3\n",
        "  return np.NAN\n",
        "\n",
        "df['target'] = df.apply(get_class, axis=1)\n",
        "df = df.drop(columns=['revenue'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8SZFnrdl3Bu"
      },
      "source": [
        "## Извлечение и преобразование признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_eJ9fe1l3Bv"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "class PreprocessingTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        return\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Жанры\n",
        "        self.genres_mlb = MultiLabelBinarizer().fit(X['genres'].values)\n",
        "        # Продюсерская компания\n",
        "        self.production_company_encoder = LabelEncoder().fit(X['production_company'].values)\n",
        "        # Страна производства\n",
        "        self.production_country_encoder = LabelEncoder().fit(X['production_country'].values)\n",
        "        # Дистрибьютор\n",
        "        self.domestic_distributor_encoder = LabelEncoder().fit(X['domestic_distributor'].values)\n",
        "        # Режиссер\n",
        "        self.director_encoder = LabelEncoder().fit(X['director'].values)\n",
        "        # Актеры\n",
        "        unique_actors = pd.concat([df['actor_1'], df['actor_2'], df['actor_3']]).unique()\n",
        "        self.actor_encoder = LabelEncoder().fit(unique_actors)\n",
        "        # Месяц выхода\n",
        "        self.release_month_encoder = OneHotEncoder(sparse_output=False).fit(X['release_month'].values.reshape(-1, 1))\n",
        "        # Возрастной рейтинг\n",
        "        self.mpaa_encoder = OneHotEncoder(sparse_output=False).fit(X['mpaa'].values.reshape(-1, 1))\n",
        "        # Бюджет\n",
        "        self.budget_scaler = StandardScaler().fit(X['budget'].values.reshape(-1, 1))\n",
        "        # Длительность\n",
        "        self.runtime_scaler = StandardScaler().fit(X['runtime'].values.reshape(-1, 1))\n",
        "        # Средняя оценка\n",
        "        self.vote_average_scaler = StandardScaler().fit(X['vote_average'].values.reshape(-1, 1))\n",
        "        # Сборы в первый уикенд\n",
        "        self.domestic_opening_scaler = StandardScaler().fit(X['domestic_opening'].values.reshape(-1, 1))\n",
        "\n",
        "        self.columns_order = [\n",
        "            'actor_1', 'actor_2', 'actor_3', 'director', 'production_company', 'production_country', 'domestic_distributor', \n",
        "            'runtime', 'budget', 'vote_average', 'domestic_opening', 'poster',\n",
        "            'genre_action', 'genre_adventure', 'genre_animation',\n",
        "            'genre_comedy', 'genre_crime', 'genre_documentary', 'genre_drama',\n",
        "            'genre_family', 'genre_fantasy', 'genre_foreign', 'genre_history',\n",
        "            'genre_horror', 'genre_music', 'genre_mystery', 'genre_romance',\n",
        "            'genre_science_fiction', 'genre_thriller', 'genre_war', 'genre_western',\n",
        "            'release_month_1', 'release_month_2', 'release_month_3',\n",
        "            'release_month_4', 'release_month_5', 'release_month_6',\n",
        "            'release_month_7', 'release_month_8', 'release_month_9',\n",
        "            'release_month_10', 'release_month_11', 'release_month_12', \n",
        "            'mpaa_G', 'mpaa_NC-17', 'mpaa_PG', 'mpaa_PG-13', 'mpaa_R'\n",
        "        ]\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Жанры\n",
        "        classes = [f'genre_{x.replace(\" \", \"_\").lower()}' for x in self.genres_mlb.classes_]\n",
        "        transformed_genres = self.genres_mlb.transform(X['genres'].values)\n",
        "        X = X.join(pd.DataFrame(transformed_genres.astype(bool), X.index, classes))\n",
        "        X = X.drop(columns=['genres'], axis=1)\n",
        "        # Продюсерская компания\n",
        "        X['production_company'] = self.production_company_encoder.transform(X['production_company'].values)\n",
        "        # Страна производства\n",
        "        X['production_country'] = self.production_country_encoder.transform(X['production_country'].values)\n",
        "        # Дистрибьютор\n",
        "        X['domestic_distributor'] = self.domestic_distributor_encoder.transform(X['domestic_distributor'].values)\n",
        "        # Режиссер\n",
        "        X['director'] = self.director_encoder.transform(X['director'].values)\n",
        "        # Актеры\n",
        "        for i in range(1, 4):\n",
        "            X[f'actor_{i}'] = self.actor_encoder.transform(X[f'actor_{i}'].values)\n",
        "        # Месяц выхода\n",
        "        classes = [f'release_month_{x}' for x in self.release_month_encoder.categories_[0]]\n",
        "        transfored_release_month = self.release_month_encoder.transform(X['release_month'].values.reshape(-1, 1))\n",
        "        X = X.join(pd.DataFrame(transfored_release_month.astype(bool), X.index, classes))\n",
        "        X = X.drop(columns=['release_month'], axis=1)\n",
        "        # Возрастной рейтинг\n",
        "        classes = [('mpaa_' + x.upper()) for x in self.mpaa_encoder.categories_[0]]\n",
        "        transfored_mpaa = self.mpaa_encoder.transform(X['mpaa'].values.reshape(-1, 1))\n",
        "        X = X.join(pd.DataFrame(transfored_mpaa.astype(bool), X.index, classes))\n",
        "        X = X.drop(columns=['mpaa'], axis=1)\n",
        "        # Бюджет\n",
        "        X['budget'] = self.budget_scaler.transform(X['budget'].values.reshape(-1, 1))\n",
        "        # Длительность\n",
        "        X['runtime'] = self.runtime_scaler.transform(X['runtime'].values.reshape(-1, 1))\n",
        "        # Средняя оценка\n",
        "        X['vote_average'] = self.vote_average_scaler.transform(X['vote_average'].values.reshape(-1, 1))\n",
        "        # Сборы в первый уикенд\n",
        "        X['domestic_opening'] = self.domestic_opening_scaler.transform(X['domestic_opening'].values.reshape(-1, 1))\n",
        "\n",
        "        X = X[self.columns_order]\n",
        "\n",
        "        return X\n",
        "\n",
        "preprocess_pipeline = Pipeline(steps=[\n",
        "    ('preprocessing', PreprocessingTransformer()),\n",
        "]) \n",
        "\n",
        "X = df.drop(columns=['target'], axis=1)\n",
        "y = df['target'].to_numpy()\n",
        "\n",
        "# Fit and evaluate the model\n",
        "X = preprocess_pipeline.fit_transform(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqI1oRl3l3Bv"
      },
      "source": [
        "### Сохранение преобразования признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a0GQXtol3Bw"
      },
      "outputs": [],
      "source": [
        "import dill\n",
        "\n",
        "with open(f'{cfg.filename_prefix}_pipeline.pkl', 'wb') as f:\n",
        "    dill.dump(preprocess_pipeline, f, protocol=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92pl07eIl3Bx"
      },
      "source": [
        "# Построение и обучение моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNr4OSVdl3Bx"
      },
      "source": [
        "## Вспомогательная функциональность"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJgNlizzl3By"
      },
      "source": [
        "Опишем фукнцию, которая будет оценивать получившуюся модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij__k9mol3By"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Функция для оценки полученной модели\n",
        "def inspect_model(model, test_generator, y_true, model_name, history=None):\n",
        "  predictions = model.predict(test_generator)\n",
        "  # real_classes = y.argmax(axis=1)\n",
        "  real_classes = y_true\n",
        "  predicted_classes = predictions.argmax(axis=1)\n",
        "\n",
        "  # Exact and 1-class-away accuracy\n",
        "  real_classes = real_classes[:min(real_classes.shape[0], predicted_classes.shape[0])]\n",
        "  predicted_classes = predicted_classes[:min(real_classes.shape[0], predicted_classes.shape[0])]\n",
        "\n",
        "  diffs = abs(real_classes - predicted_classes)\n",
        "\n",
        "  exact_match = len(diffs[diffs <= 0]) / len(diffs)\n",
        "  one_class_away = len(diffs[diffs <= 1]) / len(diffs)\n",
        "  print('Exact match accuracy:', exact_match)\n",
        "  print('One class away accuracy:', one_class_away)\n",
        "\n",
        "  # Precision and recall\n",
        "  precision = precision_score(real_classes, predicted_classes, average=None)\n",
        "  recall = recall_score(real_classes, predicted_classes, average=None)\n",
        "  f1 = f1_score(real_classes, predicted_classes, average=None)\n",
        "  print(\"Precision per class:\", precision)\n",
        "  print(\"Recall per class:\", recall)\n",
        "  print(\"F1 score per class\", f1)\n",
        "\n",
        "  # Macro and Micro averaged Precision and Recall\n",
        "  macro_precision = precision_score(real_classes, predicted_classes, average='macro')\n",
        "  macro_recall = recall_score(real_classes, predicted_classes, average='macro')\n",
        "  micro_precision = precision_score(real_classes, predicted_classes, average='micro')\n",
        "  micro_recall = recall_score(real_classes, predicted_classes, average='micro')\n",
        "  macro_f1 = f1_score(real_classes, predicted_classes, average='macro')\n",
        "  micro_f1 = f1_score(real_classes, predicted_classes, average='micro')\n",
        "\n",
        "  print(\"Macro Precision:\", macro_precision)\n",
        "  print(\"Macro Recall:\", macro_recall)\n",
        "  print(\"Macro F1:\", macro_f1)\n",
        "  print(\"Micro Precision:\", micro_precision)\n",
        "  print(\"Micro Recall:\", micro_recall)\n",
        "  print(\"Micro F1:\", micro_f1)\n",
        "\n",
        "  # Confusion matrix\n",
        "  m = confusion_matrix(real_classes, predicted_classes)\n",
        "  ConfusionMatrixDisplay(m).plot()\n",
        "\n",
        "  if (history != None):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot()\n",
        "    ax.plot(history.history['val_loss'])\n",
        "    ax.set_title('Loss Function Over Epochs')\n",
        "    ax.set_ylabel('Sparse Categorical Crossentropy value')\n",
        "    ax.set_xlabel('No. epoch')\n",
        "    plt.show()\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot()\n",
        "    ax.plot(history.history['val_accuracy'])\n",
        "    ax.set_title('Accuracy Over Epochs')\n",
        "    ax.set_ylabel('Accuracy value')\n",
        "    ax.set_xlabel('No. epoch')\n",
        "    plt.show()\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  results[model_name] = {\n",
        "      'exact_match': exact_match,\n",
        "      'one_class_away': one_class_away,\n",
        "  }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy8IWXLUl3By"
      },
      "source": [
        "Также опишем класс, который будет отвечать за генерацию батчей с изображениями"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEGxRGTtl3By"
      },
      "outputs": [],
      "source": [
        "from keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import cv2\n",
        "\n",
        "def load_image(\n",
        "    path,\n",
        "    size=(96,96)\n",
        "):\n",
        "    img = image.load_img(path)\n",
        "    img = image.img_to_array(img)\n",
        "    img = cv2.resize(img, size)\n",
        "    return img\n",
        "\n",
        "class PosterGenerator(Sequence):\n",
        "    def __init__(\n",
        "        self,\n",
        "        posters,\n",
        "        labels,\n",
        "        batch_size = 32,\n",
        "        dim = (32,32),\n",
        "        shuffle = True,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.posters = posters\n",
        "        self.labels = labels\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.posters))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.posters) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        X = np.empty((self.batch_size, *self.dim, 3), dtype=np.float32)\n",
        "        y = np.empty((self.batch_size), dtype=np.int64)\n",
        "\n",
        "        for i, idx in enumerate(indexes):\n",
        "            X[i,] = load_image(\n",
        "                path=self.posters[idx],\n",
        "                size=self.dim,\n",
        "            )\n",
        "            y[i] = self.labels[idx]\n",
        "\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ1E1Ga5l3Bz"
      },
      "source": [
        "Опишем класс для генерации данных для таблично-постерной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLzHM7Trl3B0"
      },
      "outputs": [],
      "source": [
        "from keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import cv2\n",
        "\n",
        "def load_image(\n",
        "    path,\n",
        "    size=(96,96)\n",
        "):\n",
        "    img = image.load_img(path)\n",
        "    img = image.img_to_array(img)\n",
        "    img = cv2.resize(img, size)\n",
        "    return img\n",
        "\n",
        "class TabularPosterGenerator(Sequence):\n",
        "    def __init__(\n",
        "        self,\n",
        "        tabular,\n",
        "        posters,\n",
        "        labels,\n",
        "        batch_size = 32,\n",
        "        dim = (32,32),\n",
        "        shuffle = True,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.tabular = tabular\n",
        "        self.posters = posters\n",
        "        self.labels = labels\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.posters))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.posters) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        Xt = np.empty((self.batch_size, self.tabular.shape[1]), dtype=np.float32)\n",
        "        Xp = np.empty((self.batch_size, *self.dim, 3), dtype=np.float32)\n",
        "        y = np.empty((self.batch_size), dtype=np.int64)\n",
        "\n",
        "        for i, idx in enumerate(indexes):\n",
        "            Xt[i,] = self.tabular[idx]\n",
        "            Xp[i,] = load_image(\n",
        "                path=self.posters[idx],\n",
        "                size=self.dim,\n",
        "            )\n",
        "            y[i] = self.labels[idx]\n",
        "\n",
        "        return (Xt, Xp), y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrQ353O_l3B0"
      },
      "source": [
        "Кастомные слой для построения моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5Dm96hrl3B0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class SliceLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, start_index, **kwargs):\n",
        "        super(SliceLayer, self).__init__(**kwargs)\n",
        "        self.start_index = start_index\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Your custom slicing logic goes here\n",
        "        return inputs[:, self.start_index:]\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(SliceLayer, self).get_config()\n",
        "        config.update({\n",
        "            \"start_index\": self.start_index,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "@keras.saving.register_keras_serializable()\n",
        "class IndexAndExpandLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, index, **kwargs):\n",
        "        super(IndexAndExpandLayer, self).__init__(**kwargs)\n",
        "        self.index = index\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.expand_dims(inputs[:,self.index],-1)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(IndexAndExpandLayer, self).get_config()\n",
        "        config.update({\n",
        "            \"index\": self.index,\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrlEQX74l3B0"
      },
      "source": [
        "Кастомная метрика для отображения \"1-class-away\" точности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUm_ZBTsl3B0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the custom metric\n",
        "@keras.saving.register_keras_serializable()\n",
        "class OneClassAwayAccuracy(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='one_class_away_accuracy', **kwargs):\n",
        "        super(OneClassAwayAccuracy, self).__init__(name=name, **kwargs)\n",
        "        self.total = self.add_weight(name='total', initializer='zeros')\n",
        "        self.count = self.add_weight(name='count', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Convert predictions to class indices\n",
        "        y_pred = tf.argmax(y_pred, axis=1)\n",
        "        y_true = tf.squeeze(y_true)\n",
        "\n",
        "        # Determine correct predictions within one class\n",
        "        correct = tf.cast(\n",
        "            tf.math.logical_or(\n",
        "                tf.equal(y_true, y_pred),\n",
        "                tf.logical_or(\n",
        "                    tf.equal(y_true, y_pred + 1),\n",
        "                    tf.equal(y_true, y_pred - 1)\n",
        "                )\n",
        "            ),\n",
        "            tf.float32\n",
        "        )\n",
        "\n",
        "        if sample_weight is not None:\n",
        "            sample_weight = tf.cast(sample_weight, tf.float32)\n",
        "            correct = tf.multiply(correct, sample_weight)\n",
        "\n",
        "        self.total.assign_add(tf.reduce_sum(correct))\n",
        "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        return tf.math.divide_no_nan(self.total, self.count)\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.total.assign(0)\n",
        "        self.count.assign(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp3N6Z21l3B1"
      },
      "source": [
        "Расчет весов классов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G5nQfpLl3B1"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "class_weights = {i: x for i, x in enumerate(class_weights)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnKoEh3-l3B1"
      },
      "source": [
        "Разбиваем исходный датасет следующим образом: 90% - тренировочный, 5% - валидационный, 5% - тестовый."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz-I2Givl3B1",
        "outputId": "f98814d0-4b4d-4b72-beef-ef8a1ff19b73"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_dum, y_train, y_dum = train_test_split(X, y, test_size=1-cfg.train_size, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_dum, y_dum, test_size=cfg.test_size/(cfg.test_size + cfg.val_size), stratify=y_dum)\n",
        "\n",
        "print('Train size:', cfg.train_size)\n",
        "print('Test size:', (1-cfg.train_size) * cfg.test_size/(cfg.test_size + cfg.val_size))\n",
        "print('Val size:', (1-cfg.train_size) * cfg.val_size/(cfg.test_size + cfg.val_size))\n",
        "\n",
        "print('Train size:', X_train.shape)\n",
        "print('Test size:', X_test.shape)\n",
        "print('Val size:', X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_F-y7VEl3B2"
      },
      "source": [
        "## Архитектура табличной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy0fvLljl3B2"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "class AdditionalModel():\n",
        "    def __init__(self, model, model_output, port, trainable):\n",
        "        self.model = model\n",
        "        self.model_output = model_output\n",
        "        self.port = port\n",
        "        self.trainable = trainable\n",
        "\n",
        "\n",
        "def build_tabular_model(\n",
        "    original_input_shape,\n",
        "    n_unique_actors,\n",
        "    n_unique_directors,\n",
        "    n_unique_production_companies,\n",
        "    n_unique_production_countries,\n",
        "    n_unique_domestic_distributor,\n",
        "    n_classes,\n",
        "    additional_model: AdditionalModel,\n",
        "):\n",
        "    def out_dim(n):\n",
        "        return 20\n",
        "\n",
        "    def build_embedding_cfg(name, input_dim, output_dim=out_dim(None)):\n",
        "        return {\n",
        "            'name': name,\n",
        "            'input_dim': input_dim,\n",
        "            'output_dim': output_dim,\n",
        "        }\n",
        "\n",
        "    input = layers.Input(shape=(original_input_shape,))\n",
        "\n",
        "    embedding_cfg = [\n",
        "        build_embedding_cfg('actor_1', n_unique_actors),\n",
        "        build_embedding_cfg('actor_2', n_unique_actors),\n",
        "        build_embedding_cfg('actor_3', n_unique_actors),\n",
        "        build_embedding_cfg('director', n_unique_directors),\n",
        "        build_embedding_cfg('production_company', n_unique_production_companies),\n",
        "        build_embedding_cfg('production_country', n_unique_production_countries),\n",
        "        build_embedding_cfg('domestic_distributor', n_unique_domestic_distributor),\n",
        "    ]\n",
        "\n",
        "    embedding_outputs = []\n",
        "    for i, cfg in enumerate(embedding_cfg):\n",
        "        embedded_lambda = IndexAndExpandLayer(i)(input)\n",
        "        embedding = layers.Embedding(\n",
        "            input_dim=cfg['input_dim'],\n",
        "            output_dim=cfg['output_dim'],\n",
        "            name=cfg['name'],\n",
        "        )(embedded_lambda)\n",
        "        output = layers.Flatten()(embedding)\n",
        "\n",
        "        embedding_outputs.append(output)\n",
        "\n",
        "    other_lambda = SliceLayer(len(embedding_cfg))(input)\n",
        "\n",
        "    to_concat = [\n",
        "        *embedding_outputs,\n",
        "        other_lambda\n",
        "    ]\n",
        "    if ((not additional_model is None) and additional_model.port == 'input'):\n",
        "        to_concat.append(additional_model.model_output)\n",
        "\n",
        "    merged = layers.concatenate(to_concat)\n",
        "\n",
        "    hidden = layers.Dense(96, activation='relu')(merged)\n",
        "    hidden = layers.Dropout(0.4)(hidden)\n",
        "    hidden = layers.Dense(64, activation='relu')(hidden)\n",
        "\n",
        "    if ((not additional_model is None) and additional_model.port == 'middle'):\n",
        "        hidden = layers.concatenate([hidden, additional_model.model_output])\n",
        "\n",
        "    hidden = layers.Dropout(0.4)(hidden)\n",
        "    hidden = layers.Dense(32, activation='relu')(hidden)\n",
        "    hidden = layers.Dropout(0.4)(hidden)\n",
        "    hidden = layers.Dense(16, activation='relu')(hidden)\n",
        "\n",
        "    if ((not additional_model is None) and additional_model.port == 'output'):\n",
        "        hidden = layers.concatenate([hidden, additional_model.model_output])\n",
        "\n",
        "    output = layers.Dense(n_classes, activation='softmax')(hidden)\n",
        "\n",
        "    inputs = input\n",
        "    if (not additional_model is None):\n",
        "        inputs = [\n",
        "            input,\n",
        "            additional_model.model.input,\n",
        "        ]\n",
        "        additional_model.model.trainable = additional_model.trainable\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ahDZ9GUl3B2"
      },
      "source": [
        "## Архитектура модели для постеров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbjfCltcl3B2"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.optimizers import Adagrad, Adam\n",
        "import dill\n",
        "\n",
        "class PosterModelWrapper():\n",
        "    def __init__(self, input_shape, n_classes):\n",
        "        inp = layers.Input(shape=input_shape)\n",
        "\n",
        "        hidden = layers.Conv2D(16, 3, activation='relu')(inp)\n",
        "        hidden = layers.BatchNormalization()(hidden)\n",
        "        hidden = layers.MaxPooling2D(pool_size=(3, 3))(hidden)\n",
        "\n",
        "        hidden = layers.Conv2D(32, 3, activation=\"relu\")(hidden)\n",
        "        hidden = layers.BatchNormalization()(hidden)\n",
        "        hidden = layers.MaxPooling2D(pool_size=(3, 3))(hidden)\n",
        "\n",
        "        hidden = layers.Conv2D(64, 3, activation=\"relu\")(hidden)\n",
        "        hidden = layers.BatchNormalization()(hidden)\n",
        "        hidden = layers.MaxPooling2D(pool_size=(3, 3))(hidden)\n",
        "\n",
        "        hidden = layers.Flatten()(hidden)\n",
        "\n",
        "        hidden = layers.Dense(128, activation='relu', name='last')(hidden)\n",
        "\n",
        "        out = layers.Dense(n_classes, activation='softmax')(hidden)\n",
        "\n",
        "        model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def train(\n",
        "        self,\n",
        "        train_generator,\n",
        "        val_generator,\n",
        "        class_weights,\n",
        "        checkpoint_path,\n",
        "    ):\n",
        "        optimizer = Adagrad(\n",
        "            learning_rate=cfg.learning_rate,\n",
        "        )\n",
        "        self.model.compile(\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy', OneClassAwayAccuracy()],\n",
        "        )\n",
        "\n",
        "        checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "        # Настраиваем callback для ранней остановки модели\n",
        "        early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=cfg.early_stopping_min_delta, patience=cfg.early_stopping_patience, verbose=1)\n",
        "        # Настраиваем callback для TensorBoardd\n",
        "        tensorboard = TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "        # Обучение модели\n",
        "        full_history = self.model.fit(\n",
        "            x=train_generator,\n",
        "            validation_data=val_generator,\n",
        "            epochs=cfg.num_epochs,\n",
        "            verbose=1,\n",
        "            callbacks=[\n",
        "                checkpoint,\n",
        "                early_stopping,\n",
        "                tensorboard,\n",
        "            ],\n",
        "        )\n",
        "        best_model = load_model(checkpoint_path)\n",
        "\n",
        "        with open(f'./{cfg.filename_prefix}_poster_only_history.pkl', 'wb') as f:\n",
        "            dill.dump(full_history, f, protocol=5)\n",
        "\n",
        "        return best_model, full_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2PeS8psl3B2"
      },
      "source": [
        "### Архитектура"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "mJdghuO5l3B2",
        "outputId": "ae8a857f-799f-48f2-cdcd-9f7d72e123cf"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "poster_model_wrapper = PosterModelWrapper(\n",
        "    input_shape=(*cfg.poster_shape, 3),\n",
        "    n_classes=cfg.num_classes,\n",
        ")\n",
        "plot_model(poster_model_wrapper.model, show_shapes=True, show_layer_activations=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI9zy59bl3B2"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hz5EwTAl3B3",
        "outputId": "36d538b7-ada4-4790-ca96-ae422a9161b8"
      },
      "outputs": [],
      "source": [
        "train_generator = PosterGenerator(\n",
        "    posters=X_train['poster'].values,\n",
        "    labels=y_train,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "val_generator = PosterGenerator(\n",
        "    posters=X_val['poster'].values,\n",
        "    labels=y_val,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "\n",
        "best_poster_model_path = f'{cfg.filename_prefix}.keras'\n",
        "if (not Path(best_poster_model_path).is_file()):\n",
        "    best_model, full_history = poster_model_wrapper.train(\n",
        "        train_generator,\n",
        "        val_generator,\n",
        "        class_weights,\n",
        "        best_poster_model_path,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjd-Pfs0l3B3"
      },
      "source": [
        "### Исследование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aDjJeSeLl3B3",
        "outputId": "c093e62e-001e-468f-e401-231bdabafa3c"
      },
      "outputs": [],
      "source": [
        "best_poster_model = load_model(best_poster_model_path)\n",
        "with open(f'./{cfg.filename_prefix}_poster_only_history.pkl', 'rb') as f:\n",
        "    full_history = dill.load(f)\n",
        "\n",
        "test_generator = PosterGenerator(\n",
        "    posters=X_test['poster'].values,\n",
        "    labels=y_test,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "# Проверка лучшей модели\n",
        "inspect_model(best_poster_model, test_generator, y_test, 'poster-only', history=full_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJl2nd-Rl3B3"
      },
      "source": [
        "## Обучение вместе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfYSueKLl3B4"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    model,\n",
        "    train_generator,\n",
        "    val_generator,\n",
        "    class_weights,\n",
        "    checkpoint_path,\n",
        "):\n",
        "    checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "    # Настраиваем callback для ранней остановки модели\n",
        "    early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=cfg.early_stopping_min_delta, patience=cfg.early_stopping_patience, verbose=1)\n",
        "    # Настраиваем callback для TensorBoardd\n",
        "    tensorboard = TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "    # Обучение модели\n",
        "    full_history = model.fit(\n",
        "        x=train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=cfg.num_epochs,\n",
        "        verbose=1,\n",
        "        callbacks=[\n",
        "            checkpoint,\n",
        "            early_stopping,\n",
        "            tensorboard,\n",
        "        ],\n",
        "    )\n",
        "    best_model = load_model(checkpoint_path)\n",
        "\n",
        "    with open(f'./{checkpoint_path}_history.pkl', 'wb') as f:\n",
        "        dill.dump(full_history, f, protocol=5)\n",
        "\n",
        "    return best_model, full_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLOft56ml3B4"
      },
      "source": [
        "### Интеграция на входном слое"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "wgD5aRSyl3B4",
        "outputId": "107ccd0f-2c7f-46fa-f2c0-c81ffbb6529c"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "tabular_and_poster_INPUT_model = build_tabular_model(\n",
        "    original_input_shape=X.shape[1]-1,\n",
        "    n_unique_actors=pd.concat([X['actor_1'], X['actor_2'], X['actor_3']]).nunique(),\n",
        "    n_unique_directors=X['director'].nunique(),\n",
        "    n_unique_production_companies=X['production_company'].nunique(),\n",
        "    n_unique_production_countries=X['production_country'].nunique(),\n",
        "    n_unique_domestic_distributor=X['domestic_distributor'].nunique(),\n",
        "    n_classes=cfg.num_classes,\n",
        "    additional_model=AdditionalModel(\n",
        "        model=best_poster_model,\n",
        "        model_output=best_poster_model.get_layer(\"last\").output,\n",
        "        port='input',\n",
        "        trainable=True,\n",
        "    ),\n",
        ")\n",
        "plot_model(tabular_and_poster_INPUT_model, show_shapes=True, show_layer_activations=True, show_layer_names=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11EGKqjll3B4",
        "outputId": "0bf18112-8732-4443-e18a-ad8018244ff0"
      },
      "outputs": [],
      "source": [
        "train_generator = TabularPosterGenerator(\n",
        "    tabular=X_train.drop('poster', axis=1).values,\n",
        "    posters=X_train['poster'].values,\n",
        "    labels=y_train,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "val_generator = TabularPosterGenerator(\n",
        "    tabular=X_val.drop('poster', axis=1).values,\n",
        "    posters=X_val['poster'].values,\n",
        "    labels=y_val,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "\n",
        "optimizer = Adagrad(\n",
        "    learning_rate=cfg.learning_rate,\n",
        ")\n",
        "tabular_and_poster_INPUT_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy', OneClassAwayAccuracy()],\n",
        ")\n",
        "\n",
        "best_tabular_and_poster_INPUT_model_path = f'{cfg.filename_prefix}_input.keras'\n",
        "if (not Path(best_tabular_and_poster_INPUT_model_path).is_file()):\n",
        "    best_model, full_history = train(\n",
        "        model=tabular_and_poster_INPUT_model,\n",
        "        train_generator=train_generator,\n",
        "        val_generator=val_generator,\n",
        "        class_weights=class_weights,\n",
        "        checkpoint_path=best_tabular_and_poster_INPUT_model_path,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lcPipfMCl3B4",
        "outputId": "01c935cc-9a25-4bb3-cd0b-1191ea1b7f26"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_tabular_and_poster_INPUT_model_path)\n",
        "with open(f'./{best_tabular_and_poster_INPUT_model_path}_history.pkl', 'rb') as f:\n",
        "    full_history = dill.load(f)\n",
        "\n",
        "test_generator = TabularPosterGenerator(\n",
        "    tabular=X_test.drop('poster', axis=1).values,\n",
        "    posters=X_test['poster'].values,\n",
        "    labels=y_test,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "# Проверка лучшей модели\n",
        "inspect_model(best_model, test_generator, y_test, best_tabular_and_poster_INPUT_model_path, history=full_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMzZNUdKl3B4"
      },
      "source": [
        "### Интеграция на промежуточном слое"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "DbzQQ8zGl3B5",
        "outputId": "e6e240cc-9dc3-42c5-b60b-1c21fedbe5f3"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "tabular_and_poster_MIDDLE_model = build_tabular_model(\n",
        "    original_input_shape=X.shape[1]-1,\n",
        "    n_unique_actors=pd.concat([X['actor_1'], X['actor_2'], X['actor_3']]).nunique(),\n",
        "    n_unique_directors=X['director'].nunique(),\n",
        "    n_unique_production_companies=X['production_company'].nunique(),\n",
        "    n_unique_production_countries=X['production_country'].nunique(),\n",
        "    n_unique_domestic_distributor=X['domestic_distributor'].nunique(),\n",
        "    n_classes=cfg.num_classes,\n",
        "    additional_model=AdditionalModel(\n",
        "        model=best_poster_model,\n",
        "        model_output=best_poster_model.get_layer(\"last\").output,\n",
        "        port='middle',\n",
        "        trainable=True,\n",
        "    ),\n",
        ")\n",
        "plot_model(tabular_and_poster_MIDDLE_model, show_shapes=True, show_layer_activations=True, show_layer_names=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm3Rs7cWl3B5",
        "outputId": "d5832f5b-02f7-43f7-e727-32b8d376cb8f"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "train_generator = TabularPosterGenerator(\n",
        "    tabular=X_train.drop('poster', axis=1).values,\n",
        "    posters=X_train['poster'].values,\n",
        "    labels=y_train,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "val_generator = TabularPosterGenerator(\n",
        "    tabular=X_val.drop('poster', axis=1).values,\n",
        "    posters=X_val['poster'].values,\n",
        "    labels=y_val,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "\n",
        "optimizer = Adam(\n",
        "    learning_rate=cfg.learning_rate,\n",
        ")\n",
        "tabular_and_poster_MIDDLE_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy', OneClassAwayAccuracy()],\n",
        ")\n",
        "\n",
        "best_tabular_poster_MIDDLE_model_path = f'{cfg.filename_prefix}_middle.keras'\n",
        "if (not Path(best_tabular_poster_MIDDLE_model_path).is_file()):\n",
        "    best_model, full_history = train(\n",
        "        model=tabular_and_poster_MIDDLE_model,\n",
        "        train_generator=train_generator,\n",
        "        val_generator=val_generator,\n",
        "        class_weights=class_weights,\n",
        "        checkpoint_path=best_tabular_poster_MIDDLE_model_path,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5HXfQ1WYl3B5",
        "outputId": "6917a2e0-0c20-48fa-c51f-a3c22985f9be"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_tabular_poster_MIDDLE_model_path)\n",
        "with open(f'./{best_tabular_poster_MIDDLE_model_path}_history.pkl', 'rb') as f:\n",
        "    full_history = dill.load(f)\n",
        "\n",
        "test_generator = TabularPosterGenerator(\n",
        "    tabular=X_test.drop('poster', axis=1).values,\n",
        "    posters=X_test['poster'].values,\n",
        "    labels=y_test,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "# Проверка лучшей модели\n",
        "inspect_model(best_model, test_generator, y_test, best_tabular_poster_MIDDLE_model_path, history=full_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUT9LVOyl3B5"
      },
      "source": [
        "### Интеграция на выходном слое"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "mY0ObuBLl3B5",
        "outputId": "5775e4e6-3d78-4d71-8fd1-95ef449c8dd0"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "tabular_and_poster_OUTPUT_model = build_tabular_model(\n",
        "    original_input_shape=X.shape[1]-1,\n",
        "    n_unique_actors=pd.concat([X['actor_1'], X['actor_2'], X['actor_3']]).nunique(),\n",
        "    n_unique_directors=X['director'].nunique(),\n",
        "    n_unique_production_companies=X['production_company'].nunique(),\n",
        "    n_unique_production_countries=X['production_country'].nunique(),\n",
        "    n_unique_domestic_distributor=X['domestic_distributor'].nunique(),\n",
        "    n_classes=cfg.num_classes,\n",
        "    additional_model=AdditionalModel(\n",
        "        model=best_poster_model,\n",
        "        model_output=best_poster_model.get_layer(\"last\").output,\n",
        "        port='output',\n",
        "        trainable=True,\n",
        "    ),\n",
        ")\n",
        "plot_model(tabular_and_poster_OUTPUT_model, show_shapes=True, show_layer_activations=True, show_layer_names=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfiepx4Vl3B5",
        "outputId": "2b6e7d39-5ff3-47aa-eb9f-297c36479c6e"
      },
      "outputs": [],
      "source": [
        "train_generator = TabularPosterGenerator(\n",
        "    tabular=X_train.drop('poster', axis=1).values,\n",
        "    posters=X_train['poster'].values,\n",
        "    labels=y_train,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "val_generator = TabularPosterGenerator(\n",
        "    tabular=X_val.drop('poster', axis=1).values,\n",
        "    posters=X_val['poster'].values,\n",
        "    labels=y_val,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "\n",
        "optimizer = Adagrad(\n",
        "    learning_rate=cfg.learning_rate,\n",
        ")\n",
        "tabular_and_poster_OUTPUT_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy', OneClassAwayAccuracy()],\n",
        ")\n",
        "\n",
        "best_tabular_and_poster_OUTPUT_model_path = f'{cfg.filename_prefix}_output.keras'\n",
        "if (not Path(best_tabular_and_poster_OUTPUT_model_path).is_file()):\n",
        "    best_model, full_history = train(\n",
        "        model=tabular_and_poster_OUTPUT_model,\n",
        "        train_generator=train_generator,\n",
        "        val_generator=val_generator,\n",
        "        class_weights=class_weights,\n",
        "        checkpoint_path=best_tabular_and_poster_OUTPUT_model_path,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2CSXB63gl3B6",
        "outputId": "b58adb02-2566-4aae-eac8-23df4d09c450"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_tabular_and_poster_OUTPUT_model_path)\n",
        "with open(f'./{best_tabular_and_poster_OUTPUT_model_path}_history.pkl', 'rb') as f:\n",
        "    full_history = dill.load(f)\n",
        "\n",
        "test_generator = TabularPosterGenerator(\n",
        "    tabular=X_test.drop('poster', axis=1).values,\n",
        "    posters=X_test['poster'].values,\n",
        "    labels=y_test,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "# Проверка лучшей модели\n",
        "inspect_model(best_model, test_generator, y_test, best_tabular_and_poster_OUTPUT_model_path, history=full_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-KaSHkOl3B6"
      },
      "source": [
        "## Обучение отдельно"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwnnKKRRl3B6"
      },
      "source": [
        "### Интеграция на входном слое"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsQc9nsDl3B6"
      },
      "outputs": [],
      "source": [
        "best_poster_model = load_model(best_poster_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "uppYRk14l3B6",
        "outputId": "c08a4438-f9b9-46d6-9be7-dc6586f46e1e"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "tabular_and_pretrained_poster_INPUT_model = build_tabular_model(\n",
        "    original_input_shape=X.shape[1]-1,\n",
        "    n_unique_actors=pd.concat([X['actor_1'], X['actor_2'], X['actor_3']]).nunique(),\n",
        "    n_unique_directors=X['director'].nunique(),\n",
        "    n_unique_production_companies=X['production_company'].nunique(),\n",
        "    n_unique_production_countries=X['production_country'].nunique(),\n",
        "    n_unique_domestic_distributor=X['domestic_distributor'].nunique(),\n",
        "    n_classes=cfg.num_classes,\n",
        "    additional_model=AdditionalModel(\n",
        "        model=best_poster_model,\n",
        "        model_output=best_poster_model.get_layer(\"last\").output,\n",
        "        port='input',\n",
        "        trainable=False\n",
        "    ),\n",
        ")\n",
        "plot_model(tabular_and_pretrained_poster_INPUT_model, show_shapes=True, show_layer_activations=True, show_layer_names=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtKweBzol3B6",
        "outputId": "2a634b39-9c26-4cab-e010-c8e300e096bd"
      },
      "outputs": [],
      "source": [
        "train_generator = TabularPosterGenerator(\n",
        "    tabular=X_train.drop('poster', axis=1).values,\n",
        "    posters=X_train['poster'].values,\n",
        "    labels=y_train,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "val_generator = TabularPosterGenerator(\n",
        "    tabular=X_val.drop('poster', axis=1).values,\n",
        "    posters=X_val['poster'].values,\n",
        "    labels=y_val,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "\n",
        "optimizer = Adagrad(\n",
        "    learning_rate=cfg.learning_rate,\n",
        ")\n",
        "tabular_and_pretrained_poster_INPUT_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy', OneClassAwayAccuracy()],\n",
        ")\n",
        "\n",
        "best_tabular_and_pretrained_poster_INPUT_model_path = f'{cfg.filename_prefix}_pretrained_input.keras'\n",
        "if (not Path(best_tabular_and_pretrained_poster_INPUT_model_path).is_file()):\n",
        "    best_model, full_history = train(\n",
        "        model=tabular_and_pretrained_poster_INPUT_model,\n",
        "        train_generator=train_generator,\n",
        "        val_generator=val_generator,\n",
        "        class_weights=class_weights,\n",
        "        checkpoint_path=best_tabular_and_pretrained_poster_INPUT_model_path,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b22myRHUl3B7",
        "outputId": "246a9ba6-8c29-4e44-8773-3de06f67ff06"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_tabular_and_pretrained_poster_INPUT_model_path)\n",
        "with open(f'./{best_tabular_and_pretrained_poster_INPUT_model_path}_history.pkl', 'rb') as f:\n",
        "    full_history = dill.load(f)\n",
        "\n",
        "test_generator = TabularPosterGenerator(\n",
        "    tabular=X_test.drop('poster', axis=1).values,\n",
        "    posters=X_test['poster'].values,\n",
        "    labels=y_test,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "# Проверка лучшей модели\n",
        "inspect_model(best_model, test_generator, y_test, best_tabular_and_pretrained_poster_INPUT_model_path, history=full_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pFLCg8fl3B7"
      },
      "source": [
        "### Интеграция на промежуточном слое"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "vw9Tfc5Al3B7",
        "outputId": "a155a0ae-2685-4027-f90b-c85add370063"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "tabular_and_pretrained_poster_MIDDLE_model = build_tabular_model(\n",
        "    original_input_shape=X.shape[1]-1,\n",
        "    n_unique_actors=pd.concat([X['actor_1'], X['actor_2'], X['actor_3']]).nunique(),\n",
        "    n_unique_directors=X['director'].nunique(),\n",
        "    n_unique_production_companies=X['production_company'].nunique(),\n",
        "    n_unique_production_countries=X['production_country'].nunique(),\n",
        "    n_unique_domestic_distributor=X['domestic_distributor'].nunique(),\n",
        "    n_classes=cfg.num_classes,\n",
        "    additional_model=AdditionalModel(\n",
        "        model=best_poster_model,\n",
        "        model_output=best_poster_model.get_layer(\"last\").output,\n",
        "        port='middle',\n",
        "        trainable=False\n",
        "    ),\n",
        ")\n",
        "plot_model(tabular_and_pretrained_poster_MIDDLE_model, show_shapes=True, show_layer_activations=True, show_layer_names=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2j5dP3il3B7",
        "outputId": "afaa2601-cf22-4c79-acc2-61fb140bdb9f"
      },
      "outputs": [],
      "source": [
        "train_generator = TabularPosterGenerator(\n",
        "    tabular=X_train.drop('poster', axis=1).values,\n",
        "    posters=X_train['poster'].values,\n",
        "    labels=y_train,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "val_generator = TabularPosterGenerator(\n",
        "    tabular=X_val.drop('poster', axis=1).values,\n",
        "    posters=X_val['poster'].values,\n",
        "    labels=y_val,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "\n",
        "optimizer = Adagrad(\n",
        "    learning_rate=cfg.learning_rate,\n",
        ")\n",
        "tabular_and_pretrained_poster_MIDDLE_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy', OneClassAwayAccuracy()],\n",
        ")\n",
        "\n",
        "best_tabular_and_pretrained_poster_MIDDLE_model_path = f'{cfg.filename_prefix}_pretrained_middle.keras'\n",
        "if (not Path(best_tabular_and_pretrained_poster_MIDDLE_model_path).is_file()):\n",
        "    best_model, full_history = train(\n",
        "        model=tabular_and_pretrained_poster_MIDDLE_model,\n",
        "        train_generator=train_generator,\n",
        "        val_generator=val_generator,\n",
        "        class_weights=class_weights,\n",
        "        checkpoint_path=best_tabular_and_pretrained_poster_MIDDLE_model_path,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vflVAWhul3B7",
        "outputId": "fc70272c-b00d-4759-e910-612aed73533c"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_tabular_and_pretrained_poster_MIDDLE_model_path)\n",
        "with open(f'./{best_tabular_and_pretrained_poster_MIDDLE_model_path}_history.pkl', 'rb') as f:\n",
        "    full_history = dill.load(f)\n",
        "\n",
        "test_generator = TabularPosterGenerator(\n",
        "    tabular=X_test.drop('poster', axis=1).values,\n",
        "    posters=X_test['poster'].values,\n",
        "    labels=y_test,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "# Проверка лучшей модели\n",
        "inspect_model(best_model, test_generator, y_test, best_tabular_and_pretrained_poster_MIDDLE_model_path, history=full_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13RI647Sl3B8"
      },
      "source": [
        "### Интеграция на выходном слое"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "5-07x4VHl3B8",
        "outputId": "9089ac77-2933-47a1-ceea-bdf21b46535b"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "\n",
        "tabular_and_pretrained_poster_OUTPUT_model = build_tabular_model(\n",
        "    original_input_shape=X.shape[1]-1,\n",
        "    n_unique_actors=pd.concat([X['actor_1'], X['actor_2'], X['actor_3']]).nunique(),\n",
        "    n_unique_directors=X['director'].nunique(),\n",
        "    n_unique_production_companies=X['production_company'].nunique(),\n",
        "    n_unique_production_countries=X['production_country'].nunique(),\n",
        "    n_unique_domestic_distributor=X['domestic_distributor'].nunique(),\n",
        "    n_classes=cfg.num_classes,\n",
        "    additional_model=AdditionalModel(\n",
        "        model=best_poster_model,\n",
        "        model_output=best_poster_model.get_layer(\"last\").output,\n",
        "        port='output',\n",
        "        trainable=False\n",
        "    ),\n",
        ")\n",
        "plot_model(tabular_and_pretrained_poster_OUTPUT_model, show_shapes=True, show_layer_activations=True, show_layer_names=True, show_trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMKrFpK4l3B8",
        "outputId": "22733c42-bc15-4670-ed2a-d2d987154ced"
      },
      "outputs": [],
      "source": [
        "train_generator = TabularPosterGenerator(\n",
        "    tabular=X_train.drop('poster', axis=1).values,\n",
        "    posters=X_train['poster'].values,\n",
        "    labels=y_train,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "val_generator = TabularPosterGenerator(\n",
        "    tabular=X_val.drop('poster', axis=1).values,\n",
        "    posters=X_val['poster'].values,\n",
        "    labels=y_val,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "\n",
        "optimizer = Adagrad(\n",
        "    learning_rate=cfg.learning_rate,\n",
        ")\n",
        "tabular_and_pretrained_poster_OUTPUT_model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=optimizer,\n",
        "    metrics=['accuracy', OneClassAwayAccuracy()],\n",
        ")\n",
        "\n",
        "best_tabular_and_pretrained_poster_OUTPUT_model_path = f'{cfg.filename_prefix}_pretrained_output.keras'\n",
        "if (not Path(best_tabular_and_pretrained_poster_OUTPUT_model_path).is_file()):\n",
        "    best_model, full_history = train(\n",
        "        model=tabular_and_pretrained_poster_OUTPUT_model,\n",
        "        train_generator=train_generator,\n",
        "        val_generator=val_generator,\n",
        "        class_weights=class_weights,\n",
        "        checkpoint_path=best_tabular_and_pretrained_poster_OUTPUT_model_path,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TQFEKm5-l3B8",
        "outputId": "820ec955-4d8d-47aa-be2b-2aa7d9a5bc50"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(best_tabular_and_pretrained_poster_OUTPUT_model_path)\n",
        "with open(f'./{best_tabular_and_pretrained_poster_OUTPUT_model_path}_history.pkl', 'rb') as f:\n",
        "    full_history = dill.load(f)\n",
        "\n",
        "test_generator = TabularPosterGenerator(\n",
        "    tabular=X_test.drop('poster', axis=1).values,\n",
        "    posters=X_test['poster'].values,\n",
        "    labels=y_test,\n",
        "    batch_size=cfg.batch_size,\n",
        "    dim=cfg.poster_shape,\n",
        ")\n",
        "# Проверка лучшей модели\n",
        "inspect_model(best_model, test_generator, y_test, best_tabular_and_pretrained_poster_OUTPUT_model_path, history=full_history)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
