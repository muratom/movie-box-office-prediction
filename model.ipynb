{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from ast import literal_eval\n",
    "from sklearn.preprocessing import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./movie_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['budget'] = df['budget'].replace({0: np.NAN})\n",
    "df.dropna(subset=['budget', 'mpaa', 'director', 'genres', 'domestic_distributor', 'production_companies', 'production_countries', 'spoken_languages'], inplace=True) \n",
    "\n",
    "df = df[df['status'] == 'Released']\n",
    "df = df.drop(columns=['status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['genres', 'production_countries', 'production_companies', 'actors', 'spoken_languages']\n",
    "\n",
    "mlb_classes = {}\n",
    "for col in cols:\n",
    "    df[col] = df.apply(lambda x: literal_eval(x[col]), axis=1)\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit_transform(df[col])\n",
    "    mlb_classes[col] = mlb.classes_\n",
    "    print(col, len(mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "dum = mlb.fit_transform(df['genres'])\n",
    "classes = ['genre_' + x.replace(' ', '_').lower() for x in mlb.classes_]\n",
    "df = df.join(pd.DataFrame(dum.astype(bool), df.index, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set(mlb.classes_)\n",
    "print('Количество жанров:', len(genres))\n",
    "print('Жанры: ', genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['genres'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(pd.DataFrame(df['actors'].values.tolist(), df.index, ['actor_1', 'actor_2', 'actor_3']))\n",
    "df = df.drop(['actors'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделяем год, месяц и день выхода фильма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "\n",
    "y = df.apply(lambda x: parse(x['release_date']).year, axis=1)\n",
    "m = df.apply(lambda x: parse(x['release_date']).month, axis=1)\n",
    "d = df.apply(lambda x: parse(x['release_date']).day, axis=1)\n",
    "\n",
    "\n",
    "df = df.join(y.rename('release_year'))\n",
    "df = df.join(m.rename('release_month'))\n",
    "df = df.join(d.rename('release_day'))\n",
    "\n",
    "df = df.drop(columns=['release_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['actor_1'].notna()]\n",
    "df = df[df['actor_2'].notna()]\n",
    "df = df[df['actor_3'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['production_companies'] = df.apply(lambda row: row['production_companies'][0], axis=1)\n",
    "df['production_countries'] = df.apply(lambda row: row['production_countries'][0], axis=1)\n",
    "df['spoken_languages'] = df.apply(lambda row: row['spoken_languages'][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding_col(col):\n",
    "    y = df['revenue'].values\n",
    "    X = df[col]\n",
    "    X = X.values.reshape(-1, 1)\n",
    "\n",
    "    enc_auto = TargetEncoder(target_type='continuous', smooth=\"auto\")\n",
    "    return enc_auto.fit_transform(X, y)\n",
    "\n",
    "\n",
    "df['production_companies'] = target_encoding_col('production_companies')\n",
    "df['production_countries'] = target_encoding_col('production_countries')\n",
    "df['spoken_languages'] = target_encoding_col('spoken_languages')\n",
    "df['actor_1'] = target_encoding_col('actor_1')\n",
    "df['actor_2'] = target_encoding_col('actor_2')\n",
    "df['actor_3'] = target_encoding_col('actor_3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['id', 'imdb_id', 'tagline', 'overview', 'vote_average', 'vote_count', 'domestic_opening'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model(input_shape):\n",
    "    input = layers.Input(shape=input_shape)\n",
    "    hidden = layers.Dense(32, activation='relu')(input)\n",
    "    hidden = layers.Dense(64, activation='relu')(hidden)\n",
    "    hidden = layers.Dense(128, activation='relu')(hidden)\n",
    "    hidden = layers.Dense(64, activation='relu')(hidden)\n",
    "    hidden = layers.Dense(32, activation='relu')(hidden)\n",
    "    output = layers.Dense(1)(hidden)\n",
    "\n",
    "    model = Model(inputs=input, outputs=output) # To define a model, just specify its input and output layers\n",
    "\n",
    "    model.compile(loss='rmsprop', optimizer='mse', metrics=['mae'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# batch_size = 32 # in each iteration, we consider 32 training examples at once\n",
    "# num_epochs = 200 # we iterate 200 times over the entire training set\n",
    "# kernel_size = 3 # we will use 3x3 kernels throughout\n",
    "# pool_size = 2 # we will use 2x2 pooling throughout\n",
    "# conv_depth_1 = 32 # we will initially have 32 kernels per conv. layer...\n",
    "# conv_depth_2 = 64 # ...switching to 64 after the first pooling layer\n",
    "# drop_prob_1 = 0.25 # dropout after pooling with probability 0.25\n",
    "# drop_prob_2 = 0.5 # dropout in the dense layer with probability 0.5\n",
    "# hidden_size = 512 # the dense layer will have 512 neurons\n",
    "\n",
    "\n",
    "# model = build_model()\n",
    "\n",
    "# # Настриваем сохранение лучшей модели\n",
    "# checkpoint_path = \"./best-model.keras\"\n",
    "# checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "# # Настраиваем callback для ранней остановки модели\n",
    "# early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=4, verbose=1)\n",
    "\n",
    "# model.fit(X_train, Y_train, # Train the model using the training set...\n",
    "\n",
    "#           batch_size=batch_size, epochs=num_epochs,\n",
    "\n",
    "#           verbose=1, validation_split=0.1) # ...holding out 10% of the data for validation\n",
    "\n",
    "# model.evaluate(X_test, Y_test, verbose=1) # Evaluate the trained model on the test set!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dict_list_to_df(s, col):\n",
    "#     rows = []\n",
    "#     for index, row in s.items():\n",
    "#         for item in row:\n",
    "#             rows.append(item)\n",
    "#     df = pd.DataFrame(rows)\n",
    "#     return df\n",
    "\n",
    "\n",
    "# df_genres = df['genres'].apply(lambda i: literal_eval(i))\n",
    "# df_genres = dict_list_to_df(df_genres, 'genres')\n",
    "# df_unique_genres = df_genres.drop_duplicates()\n",
    "# df_unique_genres.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sortArray(column):\n",
    "#     def f(row):\n",
    "#         l = row[column]\n",
    "#         l.sort()\n",
    "#         return l\n",
    "\n",
    "#     return f\n",
    "\n",
    "# df['production_companies'] = df.apply(sortArray('production_companies'), axis=1)\n",
    "# df['production_countries'] = df.apply(sortArray('production_countries'), axis=1)\n",
    "# df['spoken_languages'] = df.apply(sortArray('spoken_languages'), axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
